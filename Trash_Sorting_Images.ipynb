{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPenoOvl94ilQbDoeUUkbq1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoemiRyf/ML2_Project/blob/main/Trash_Sorting_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries "
      ],
      "metadata": {
        "id": "im6sHUag59MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtqRYPPSdnzS",
        "outputId": "03814733-c42a-4fcf-f643-e3925717fd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\t LICENSE    README.md\t train.lua  weight-init.lua\n",
            "DataLoader.lua\t model.lua  shuffle.lua  trashnet\n",
            "dataset-resized  plot.lua   test.lua\t utils.lua\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjWLsscbMqPp",
        "outputId": "5393bd05-c5da-4079-d38d-3e15d3a22162"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Ylu8ZpjooB",
        "outputId": "46f017af-5cab-41d5-988f-c983b0c8aaca"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'archive (7).zip'   dataset.zip   sample_data   trashnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip archive (7).zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSklXB7RjQvq",
        "outputId": "07c48c54-15db-44c6-a5e6-75dc90dd658b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `unzip archive (7).zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "T2aBjWgi5Wsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/garythung/trashnet.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8ooij2JCHh-",
        "outputId": "6cfac275-7a7f-4f68-da49-22e98e991ba3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trashnet'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 45 (delta 6), reused 0 (delta 0), pack-reused 33\u001b[K\n",
            "Unpacking objects: 100% (45/45), 40.64 MiB | 18.12 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/trashnet/data\n"
      ],
      "metadata": {
        "id": "KeiVxlYdFLuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/trashnet/data/dataset-resized.zip'\n",
        "destination_folder = '/content/trashnet/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_folder)\n"
      ],
      "metadata": {
        "id": "4-YGvBnunXCY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DtOixu_nW2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python resize.py\n"
      ],
      "metadata": {
        "id": "2ZAk3Y-fFN3D"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define image data generator for training and validation data"
      ],
      "metadata": {
        "id": "kUq8hFw36yLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image data generator for training and validation data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load your dataset\n",
        "train_set = train_datagen.flow_from_directory('/content/trashnet/data/dataset-resized',\n",
        "                                              target_size=(64, 64),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MAtHoLo5z74",
        "outputId": "71428204-b320-4efe-e625-ae41c3f68f98"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2527 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "Cs_Gqk_r60Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=6, activation='softmax'))  # 3 units for 3 classes: recyclable, compostable, or trash\n"
      ],
      "metadata": {
        "id": "h2kB6s3H66nV"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile Model"
      ],
      "metadata": {
        "id": "k6taULlV7Bm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile your model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "q57Ue96t7DjF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "UKflyuyA7F2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model\n",
        "model.fit(train_set, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSO9itMO7FKe",
        "outputId": "80c2be66-efe7-4056-afc7-2d7cd68ccbd1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "79/79 [==============================] - 14s 170ms/step - loss: 2.0736 - accuracy: 0.3114\n",
            "Epoch 2/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 1.4238 - accuracy: 0.4278\n",
            "Epoch 3/25\n",
            "79/79 [==============================] - 13s 166ms/step - loss: 1.3245 - accuracy: 0.4769\n",
            "Epoch 4/25\n",
            "79/79 [==============================] - 13s 168ms/step - loss: 1.2922 - accuracy: 0.5038\n",
            "Epoch 5/25\n",
            "79/79 [==============================] - 13s 166ms/step - loss: 1.2201 - accuracy: 0.5299\n",
            "Epoch 6/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 1.1573 - accuracy: 0.5647\n",
            "Epoch 7/25\n",
            "79/79 [==============================] - 14s 178ms/step - loss: 1.1282 - accuracy: 0.5706\n",
            "Epoch 8/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 1.0778 - accuracy: 0.6035\n",
            "Epoch 9/25\n",
            "79/79 [==============================] - 13s 166ms/step - loss: 1.0298 - accuracy: 0.6146\n",
            "Epoch 10/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 0.9864 - accuracy: 0.6300\n",
            "Epoch 11/25\n",
            "79/79 [==============================] - 13s 170ms/step - loss: 0.9845 - accuracy: 0.6367\n",
            "Epoch 12/25\n",
            "79/79 [==============================] - 14s 175ms/step - loss: 0.9222 - accuracy: 0.6597\n",
            "Epoch 13/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 0.9135 - accuracy: 0.6731\n",
            "Epoch 14/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 0.8793 - accuracy: 0.6787\n",
            "Epoch 15/25\n",
            "79/79 [==============================] - 13s 166ms/step - loss: 0.8796 - accuracy: 0.6755\n",
            "Epoch 16/25\n",
            "79/79 [==============================] - 13s 165ms/step - loss: 0.8513 - accuracy: 0.6981\n",
            "Epoch 17/25\n",
            "79/79 [==============================] - 13s 165ms/step - loss: 0.8033 - accuracy: 0.7119\n",
            "Epoch 18/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 0.8106 - accuracy: 0.7020\n",
            "Epoch 19/25\n",
            "79/79 [==============================] - 13s 165ms/step - loss: 0.7750 - accuracy: 0.7242\n",
            "Epoch 20/25\n",
            "79/79 [==============================] - 14s 176ms/step - loss: 0.7544 - accuracy: 0.7301\n",
            "Epoch 21/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 0.7171 - accuracy: 0.7495\n",
            "Epoch 22/25\n",
            "79/79 [==============================] - 13s 168ms/step - loss: 0.7277 - accuracy: 0.7388\n",
            "Epoch 23/25\n",
            "79/79 [==============================] - 14s 171ms/step - loss: 0.7079 - accuracy: 0.7483\n",
            "Epoch 24/25\n",
            "79/79 [==============================] - 13s 166ms/step - loss: 0.7040 - accuracy: 0.7550\n",
            "Epoch 25/25\n",
            "79/79 [==============================] - 13s 167ms/step - loss: 0.6612 - accuracy: 0.7649\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc1fb97670>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "KfYCmVBq7MLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your model\n",
        "model.save('/content/trashnet/trash_classifier.h5')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Download the model file\n",
        "files.download('/content/trashnet/trash_classifier.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8a1T2PNp7POU",
        "outputId": "701a4009-3507-4746-afc1-a14d39f6c59d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_91787a47-c245-4810-a7e0-f92809d8a675\", \"trash_classifier.h5\", 47289984)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the test image\n",
        "test_image_path = '/content/trashnet/test_images/glass.jpg'\n",
        "test_image = Image.open(test_image_path)\n",
        "target_size = (64, 64)\n",
        "test_image = test_image.resize(target_size)\n",
        "test_image = np.array(test_image) / 255.0\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Make predictions on the test image\n",
        "predictions = model.predict(test_image)\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "# Map the predicted class index to the corresponding class label\n",
        "class_labels = train_set.class_indices\n",
        "predicted_class_label = {v: k for k, v in class_labels.items()}[predicted_class_index]\n",
        "\n",
        "# Print the predicted class label\n",
        "print('Predicted class:', predicted_class_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6QUOFn4Y_A8",
        "outputId": "20cb8edb-709e-4b70-fa6b-2fcb530d1168"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 85ms/step\n",
            "Predicted class: glass\n"
          ]
        }
      ]
    }
  ]
}